{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7c18c-3c35-4f1f-be57-866866957365",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: In this question, you have to scrape data using the filters available on the webpage You have to use the location and  \n",
    "salary filter.  \n",
    "You have to scrape data for “Data Scientist” designation for ffrst 10 job results.  \n",
    "You have to scrape the job title, job location, company name, experience required.  \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs  \n",
    "The task will be done as shown in the below steps: \n",
    "1. First get the web page https://www.naukri.com/  \n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.  \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary field by checking the respective boxes  \n",
    "5. Then scrape the data for the first 10 jobs results you get.  \n",
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e684483-b262-4919-8e6d-25ee95bc18f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')\n",
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab39c78b-453f-4126-b447-edb80ce5f2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f15dd15-bc67-46b5-b808-7e93541c0933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_filter=driver.find_element(By.XPATH,\"//span[text()='Delhi / NCR']\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c3e508a-d31e-45da-a863-d066c3fa1052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element(By.XPATH, \"//span[text()='3-6 Lakhs']\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e250e8c6-3cfc-4951-9a7a-f3a10ae8e81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b519d068-bcdb-4cbb-967e-bde929d2180b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title \"]')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\" comp-name mw-25\"]')\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5b615531-7d11-46d7-bb10-f76916dfd9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Title']=job_title[0:10]\n",
    "jobs['company']=company_name[0:10]\n",
    "jobs['experience_required']=experience_required[0:10]\n",
    "jobs['location']=job_location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06a453f2-ea0a-4c59-b1f0-8009021fe5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nityo Infotech</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (AI/ML)|| US Based MNC || Noida</td>\n",
       "      <td>Collegedunia</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Hybrid - Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Growthjockey</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Biz Tech Consultants</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Biz Tech Consultants</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Biz Tech Consultants</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>PayU</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title               company  \\\n",
       "0                                  Data Scientist        Nityo Infotech   \n",
       "1  Data Scientist (AI/ML)|| US Based MNC || Noida          Collegedunia   \n",
       "2                                  Data Scientist          Growthjockey   \n",
       "3                                    Data Analyst  Biz Tech Consultants   \n",
       "4                                    Data Analyst  Biz Tech Consultants   \n",
       "5                                                  Biz Tech Consultants   \n",
       "6                                                                  PayU   \n",
       "7                                                            Innovaccer   \n",
       "8                                  Data Scientist                   IBM   \n",
       "9                                  Data scientist        Times Internet   \n",
       "\n",
       "  experience_required                                           location  \n",
       "0             3-7 Yrs  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...  \n",
       "1             3-5 Yrs                                     Hybrid - Noida  \n",
       "2             0-2 Yrs                                           Gurugram  \n",
       "3             0-5 Yrs                                          New Delhi  \n",
       "4             0-1 Yrs                                           Gurugram  \n",
       "5             2-6 Yrs  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...  \n",
       "6             3-8 Yrs                                           Gurugram  \n",
       "7             3-8 Yrs                                          Ghaziabad  \n",
       "8             3-8 Yrs                                              Noida  \n",
       "9             2-7 Yrs                                Gurugram, Bengaluru  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfd5cc-5b6b-4214-a5f5-f6779331374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: Write a python program to scrape data for “Data Scienttst” Job positton in “Bangalore” locatton. You have to scrape the \n",
    "job-tttle, job-locatton, company_name, experience_required. You have to scrape ffrst 10 jobs data. \n",
    " This task will be done in following steps: \n",
    " 1. First get the webpage https://www.shine.com/ \n",
    " 2. Enter “Data Analyst” in “Job tttle, Skills” ffeld and enter “Bangalore” in “enter the locatton” ffeld. \n",
    " 3. Then click the searchbutton. \n",
    " 4. Then scrape the data for the ffrst 10 jobs results you get. \n",
    " 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423bcff-0963-4dbf-aa4a-7cd3cd012aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.shine.com/')\n",
    "job_title = driver.find_element(By.XPATH, \"//input[@placeholder='Job title, skills']\")\n",
    "job_title.send_keys('Data Analyst')\n",
    "location_input = driver.find_element(By.XPATH, \"//input[@placeholder='Location']\")\n",
    "location_input.send_keys('Bangalore')\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@type='submit']\")\n",
    "search_button.click()\n",
    "jobs = driver.find_elements(By.XPATH, \"//li[@class='result-display__profile ']\")[:10]\n",
    "job_data = []\n",
    "for job in jobs:\n",
    "    title = job.find_element(By.XPATH, \".//h3\").text\n",
    "    company = job.find_element(By.XPATH, \".//div[@class='result-display__profile__company-name']\").text\n",
    "    location = job.find_element(By.XPATH, \".//div[@class='result-display__profile__location']\").text\n",
    "    experience = job.find_element(By.XPATH, \".//div[@class='result-display__profile__experience']\").text\n",
    "\n",
    "    job_data.append({\n",
    "        \"Job Title\": title,\n",
    "        \"Company Name\": company,\n",
    "        \"Location\": location,\n",
    "        \"Experience Required\": experience\n",
    "    })\n",
    "\n",
    "# Print the data\n",
    "for job in job_data:\n",
    "    print(job)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9746c9-3d86-4b91-9fcc-ec8b2d906538",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Scrape 100 reviews data from fLipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    "LIPKART\n",
    "1. Rating \n",
    "2. Review summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100reviews. \n",
    "Note: All the steps required during scraping should be done through code only and not manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d8856c-5752-4da9-9468-40c0b927cd03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814ebfb-a590-4e8f-82a2-3c8772f9aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Error: page has been removed or deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943b348-194d-454d-ade2-df05e48e9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search \n",
    "field. \n",
    "You have to scrape 3 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "As shown in the below image, you have to scrape the above attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf42c6-2f62-42d5-8422-4672670ca91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(2)\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "search_field_designation=driver.find_element(By.CLASS_NAME,'Pke_EE')\n",
    "search_field_designation.send_keys(\"sneakers\")\n",
    "search_button=driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search_button.click()\n",
    "brand_tags=driver.find_elements(By.XPATH,'//a[@class=\"fxf7w6 rgHxCQ\"]')\n",
    "brand_tags[0:4]\n",
    "for i in brand_tags:\n",
    "    title=i.text\n",
    "    brand.append(title)\n",
    "brand[0:4]\n",
    "desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "desc_tags[0:4]\n",
    "for i in desc_tags:\n",
    "    title=i.text\n",
    "    product_desc.append(title)\n",
    "product_desc[0:4]\n",
    "price_tags=driver.find_elements(By.XPATH,'//a[@class=\"_30jeq3\"]')\n",
    "price_tags[0:4]\n",
    "for i in price_tags:\n",
    "    title=i.text\n",
    "    price.append(title)\n",
    "price[0:4]\n",
    "next_button=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "next_button.click()\n",
    "brand_tags1=driver.find_elements(By.XPATH,'//a[@class=\"fxf7w6 rgHxCQ\"]')\n",
    "brand_tags1[0:4]\n",
    "for i in brand_tags1:\n",
    "    title=i.text\n",
    "    brand.append(title)\n",
    "brand[0:4]\n",
    "desc_tags1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "desc_tags1\n",
    "for i in desc_tags1:\n",
    "    title=i.text\n",
    "    product_desc.append(title)\n",
    "product_desc[0:4]\n",
    "price_tags=driver.find_elements(By.XPATH,'//a[@class=\"_30jeq3\"]')\n",
    "price_tags[0:4]\n",
    "for i in price_tags:\n",
    "    title=i.text\n",
    "    price.append(title)\n",
    "price[0:4]\n",
    "brand_tags1=driver.find_elements(By.XPATH,'//a[@class=\"fxf7w6 rgHxCQ\"]')\n",
    "brand_tags1[0:4]\n",
    "for i in brand_tags1:\n",
    "    title=i.text\n",
    "    brand.append(title)\n",
    "brand[0:4]\n",
    "desc_tags1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "desc_tags1[0:4]\n",
    "for i in desc_tags1:\n",
    "    title=i.text\n",
    "    product_desc.append(title)\n",
    "product_desc[0:4]\n",
    "price_tags=driver.find_elements(By.XPATH,'//a[@class=\"_30jeq3\"]')\n",
    "price_tags[0:4]\n",
    "for i in price_tags:\n",
    "    title=i.text\n",
    "    price.append(title)\n",
    "price[0:4]\n",
    "sneakers=pd.DataFrame()\n",
    "sneakers['Brand']=brand[0:100]\n",
    "sneakers['Product Description']=product_desc[0:100]\n",
    "sneakers['Price']=price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b3a07-b44d-4647-b1c8-5f73c66d5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU \n",
    "Type filter to “Intel Core i7” as shown in the below image: \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "357272a9-6f4d-4382-819f-27eb7cc52acb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td>46,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire Lite 12th Gen Intel Core i7-1255U ...</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer ALG Gaming Laptop 13th Gen Intel Core i7 ...</td>\n",
       "      <td>46,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6\" (39.62cm) FHD, Intel C...</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 3530 Laptop, 13th Generation Int...</td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Aspire Lite 12th Gen Intel Core i7-1255U ...</td>\n",
       "      <td>67,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI Thin 15, Intel Core i7-12650H, 40CM FHD 14...</td>\n",
       "      <td>48,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td>63,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\" (39.62cm) FHD 144Hz...</td>\n",
       "      <td>39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...</td>\n",
       "      <td>1,03,980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product     Price\n",
       "0  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...    46,990\n",
       "1  Acer Aspire Lite 12th Gen Intel Core i7-1255U ...    59,990\n",
       "2  Acer ALG Gaming Laptop 13th Gen Intel Core i7 ...    46,990\n",
       "3  ASUS Vivobook 15, 15.6\" (39.62cm) FHD, Intel C...    67,990\n",
       "4  Dell Inspiron 3530 Laptop, 13th Generation Int...    56,990\n",
       "5  Acer Aspire Lite 12th Gen Intel Core i7-1255U ...    67,490\n",
       "6  MSI Thin 15, Intel Core i7-12650H, 40CM FHD 14...    48,990\n",
       "7  Acer Travelmate Business Laptop Intel Core i7-...    63,790\n",
       "8  ASUS TUF Gaming F15, 15.6\" (39.62cm) FHD 144Hz...    39,990\n",
       "9  ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...  1,03,980"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.amazon.in/')\n",
    "search_field = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "search_field.send_keys('Laptop')\n",
    "search_button = driver.find_element(By.ID, 'nav-search-submit-button')\n",
    "search_button.click()\n",
    "cpu_filter=driver.find_element(By.XPATH,\"//span[contains(text(),'Intel Core i7')]\")\n",
    "cpu_filter.click()\n",
    "brand=[]\n",
    "ratings=[]\n",
    "price=[]\n",
    "brand_tags = driver.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in brand_tags:\n",
    "    title = i.text\n",
    "    brand.append(title)\n",
    "\n",
    "ratings_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "for i in ratings_tags:\n",
    "    title = i.text\n",
    "    ratings.append(title)\n",
    " \n",
    "price_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags:\n",
    "    title = i.text\n",
    "    price.append(title)\n",
    "    \n",
    "i7_data=pd.DataFrame()\n",
    "i7_data['Product']=brand[0:10]\n",
    "i7_data['Price']=price[0:10]\n",
    "\n",
    "i7_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82bdf2-cc72-4916-b0cb-b5a5948a160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time. \n",
    "The above task will be done in following steps: \n",
    "1. First get the webpagehttps://www.azquotes.com/ \n",
    "2. Click on Top Quote \n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df5a204-4218-4d67-b751-5e6ca17c41f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                               Type of Quote  \n",
       "0   Essence, Deep Thought, Transcendentalism  \n",
       "1                  Inspiration, Past, Trying  \n",
       "2                        Country, Peace, War  \n",
       "3         Inspirational, Motivational, Death  \n",
       "4               4th Of July, Food, Patriotic  \n",
       "..                                       ...  \n",
       "95                    Music, Sports, Hunting  \n",
       "96             Trust, Encouraging, Uplifting  \n",
       "97              Inspirational, Funny, Change  \n",
       "98                      Success, God, Mother  \n",
       "99       Inspirational, Motivational, Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.azquotes.com/')\n",
    "top_quotes_button = driver.find_element(By.XPATH, '//a[contains(@href, \"top_quotes\")]')\n",
    "top_quotes_button.click()\n",
    "quotes = []\n",
    "authors = []\n",
    "quote_types = []\n",
    "quotes_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quotes_tags:\n",
    "    title = i.text\n",
    "    quotes.append(title)\n",
    "\n",
    "authors_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in authors_tags:\n",
    "    title = i.text\n",
    "    authors.append(title)\n",
    " \n",
    "quote_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in quote_tags:\n",
    "    title = i.text\n",
    "    quote_types.append(title)\n",
    "\n",
    "data = pd.DataFrame({'Quote': quotes, 'Author': authors, 'Type of Quote': quote_types})\n",
    "data.to_csv('top_quotes.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99737a36-1704-4839-84ce-69ff846df367",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name, \n",
    "Born-Dead, Term of office, Remarks) from \n",
    "\n",
    "https://www.jagranjosh.com/general-knowledge/list-ofall-prime-ministers-of-india-1473165149-1\n",
    "\n",
    " scrap the menttoned data and make the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e714e-236e-4a4d-884f-260cbe1a487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.jagranjosh.com/general-knowledge/list-ofall-prime-ministers-of-india-1473165149-1')\n",
    "data = []\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"TableData\"')\n",
    "\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cols) == 4:  # Ensure there are 4 columns in the row\n",
    "        name = cols[0].text\n",
    "        born_dead = cols[1].text\n",
    "        term_of_office = cols[2].text\n",
    "        remarks = cols[3].text\n",
    "        data.append([name, born_dead, term_of_office, remarks])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Born-Dead', 'Term of Office', 'Remarks'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b2fdd-c16b-41aa-9b7f-5d00f0723b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: Write a python program to display list of 50 Most expensive cars in the world \n",
    "(i.e. Car name and Price) from https://www.motor1.com/ \n",
    "  \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.motor1.com/ \n",
    "2. Then You have to type in the search bar ’50 most expensive cars’ \n",
    "3. Then click on 50 most expensive cars in the world.. \n",
    "4. Then scrap the mentioned data and make the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67060fda-7b55-4b3f-a930-4837e4983ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.motor1.com/')\n",
    "search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"input[placeholder='Search']\"))  # Using CSS selector for search bar\n",
    "    )\n",
    "search_bar.send_keys('50 most expensive cars')\n",
    "search_bar.submit()\n",
    "result = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, '50 Most Expensive Cars In The World'))\n",
    "    )\n",
    "car_names = driver.find_elements(By.XPATH, '//h3')  \n",
    "car_prices = driver.find_elements(By.XPATH, '//p[contains(text(), \"$\")]'\n",
    "\n",
    "data = []\n",
    "for name, price in zip(car_names, car_prices):\n",
    "  data.append([name.text, price.text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Car Name', 'Price'])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
